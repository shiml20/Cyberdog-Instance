# 				第11组 决赛文档 Cyberdog Document



[toc]

## Ⅰ 解决方案 Task Solution

### 思路

整体思路采用不带回报的马尔科夫决策思路，涉及到的数学知识和思想有以下内容：

- 卷积均值

$$
\text{Depth(mean)}=\frac{\sum_{x,y}Depth(x,y)}{||Depth(x,y)||}
$$

- 不带回报的马尔科夫决策过程

  不带回报的马尔科夫决策过程由三元组表示
  $$
  (\bold{S}, \bold{A}, \bold{P}_\pi) \\
  \bold{S}=\{ s_1=寻球过程, s_2=避障过程, s_3=空间自旋转过程,s_4=球已找到状态,s_5=其他状态 \} \\
  \bold{A}=\{a_1=旋转，a_2=前进，a_3=趴下, a_4=起立, a_5=其他行动\} \\
  \bold{P}_\pi\xleftrightarrow{\text{Define By}} \pi
  $$

- 随机数决策：空间自旋转过程 $\bold{C}$

$$
P(\text{Anti-Clockwise Rotate}\ |\ S_t=s_3) = 0.5 \\
P(\text{Clockwise Rotate}\ |\ S_t=s_3) = 0.5
$$

- 线性空间、不变子空间、线性映射

状态空间总可以表示为线性空间，因为环境是二维带障碍的有解空间，基向量选为正交的为 $\vec{x}$ 和 $\vec{y}$。设解空间为 $\bold{Y}$，则易知解空间是状态空间的子集，即$\bold{Y} \subseteq \bold{U}$。游戏的目标是通过特定的$\bold{P}_{\pi}$，采取特定的$a_t\in\bold{A}$，达到特定的$s_t \in \bold{S}$。最终达到解状态。
$$
p^a(s^\prime) = \pi(a|s)p(s)
$$
设不变子空间为 $\bold{S}_{sub}$，$\bold{S}_{sub}\subset \bold{S}$，$\bold{S}_{sub}\cap \bold{Y}=\bold{\varnothing} $狗在一定行动下可能会陷入不变子空间，而无法达到解空间，因而设置了空间自旋转过程，用于跳出不变子空间。
$$
\bold{S}^\prime \subseteq \bold{S}_{sub},\ \bold{S}^\prime是狗在没有空间自旋转过程的下一个状态所能达到的空间
$$

$$
\bold{S}^\prime \xrightarrow{\bold{C}}\bold{S}-\bold S_{sub}
$$

### 策略 

机器狗的行动策略可分阶段描述如下：

### 1.初始化阶段

机器狗执行站立过程，通过发送控制指令实现站立姿态，并发送改变步态的目标指令，选择指定的步态模式。
之后机器狗进入主体控制阶段。

### 2.主体控制阶段

机器狗在每帧调用`rgb_info()`使用摄像头获取图像信息，进行颜色识别与圆形筛选，判断视野中是否存在球。
&emsp;**若视野中存在球**，调用`depth_info()`获取深度信息，判断球的距离是否小于要求的范围。
&emsp;&emsp;-如果球的距离足够近，则执行坐下动作，机器狗进入结束阶段。
&emsp;&emsp;-如果球的距离不够近，则机器狗进入寻球模式。
&emsp;&emsp;&emsp;--在寻球模式中，使用 PID 控制器持续进行球的追踪，根据球的位置信息调整机器狗的线/角速度实现跟随动作，直到球足够近或前方出现障碍物时，跳出寻球模式。
&emsp;**若视野中不存在球**，则接下来调用`depth_info_box`判断视野中是否存在障碍物。
&emsp;&emsp;**若视野中存在障碍物**，则进入避障逻辑：
&emsp;&emsp;&emsp;-如果之前已经看到球，则执行平移避障动作。
&emsp;&emsp;&emsp;-如果还未看到球：当障碍物距离过近（深度信息低于阈值）时，执行后退避障动作；否则，执行旋转避障动作。
&emsp;&emsp;**若视野中不存在球和障碍物**，则机器狗执行前进动作。
&emsp;&emsp;&emsp;--如果前进过久而没有发现球或障碍物，机器狗将进行120度旋转，尝试寻找球并避免进入死循环。

### 3.结束阶段

机器狗执行`rest()`动作，进入趴下状态，完成比赛流程。

### 感知

#### 信息来源

RGB相机、深度相机

#### 基本思路

考虑到决赛阶段障碍物和目标球的随机性，机器狗无法事先获取全部的场地信息，视觉图像便成为机器狗高效获取信息的方式。因此视觉感知是感知部分的关键组成。

视觉感知由RGB图像和深度图像组成

- RGB图像用于感知蓝色信息、获取蓝球的相对位置，是关系到狗能否找到球的关键因素，因此对于RGB图像的处理需要兼顾准确性、稳定性和高效性。考虑到神经网络对设备的性能由一定要求，且针对视频流处理速度较缓慢，因此选择传统图像处理的方式。基本策略是限制颜色范围、滤波去噪、连通区域检测等。

- 深度图像用以捕捉三维信息，可以有效辅助机器狗决策。在比赛过程中，机器狗需要通过不断地避障来寻球，而深度图像提供了丰富的信息来探知障碍物的距离，因此深度信息避障的关键部分。此外，深度图像还可以作为任务终点的检测手段，在RGB图像感知到球的位置后，用深度图像来判断球的深度，当深度小于一定阈值时，即可认为完成了任务。

#### 核心函数

- ` rgb_info_ball `

  - 函数效果：

    - 寻找RGB图像中的蓝色球，并返回蓝色球的圆心及像素半径。

  - 实现思路：

    - 单次启用RGB相机节点，获取最新的RGB图像。
    - 将获取的RGB图像转换到HSV空间，以颜色(蓝色)作为阈值判断根据，获取掩膜信息。
    - 获取掩膜中各连通分支的轮廓信息，为增强识别的稳定性及可靠性，先将连通区域的面积作为初步筛选的条件，再从满足条件的连通区域中选择面积最大的一块。
    - 以选择到最大置信区域为基准，拟合最小包围圆，以区域面积和包围圆面积的比值作为最后的筛选条件，满足该条件后即可认为找到了蓝色球。

  - 超参数：

    - area_threshold：连通区域面积的下限阈值

    - area_ratio：连通区域面积和其包围圆面积比值

- ` depth_info_ball `

  - 函数效果：
    - 获取识别到的球的深度，返回是否离球足够近。
  - 实现思路：
    - 单次启用深度相机节点，获取最新的深度图像。
    - 根据识别到的球的包围圆的圆心和半径，计算以圆心和1/4半径区域的平均深度。后来考虑到障碍物部分遮挡球的情况，此时障碍物的深度会影响球深度的计算，因此选择直接计算深度图像中RGB最大置信区域的平均深度，这样可以有效消除上述情况的影响。
    - 设置深度上下限阈值，如果上步得到的深度在阈值范围内，表明球已经很近了。
  - 超参数：
    - upper_threshold：球深度上限阈值

    - lower_threshold：球深度下限阈值

- `  depth_info_box ` 

  - 函数效果：
    - 获取障碍物的深度，并返回障碍物是否足够近。
  - 实现思路：
    - 单次启用深度相机节点，获取最新的深度图像。
    - 将视野按横向宽度分为三块，视野高度取中央上下高80像素，分别计算三块感受野的深度。这样做的好处是能够有效识别侧方障碍物。
    - 设置深度上限阈值，如果有一块感受野的深度小于阈值了，那么表明前方或侧方遇到了障碍物。后在调试过程中发现，如果障碍物组成一横排，垂直于狗移动方向，左右两侧的识别深度是大于中间的深度的，所以增大了左右两个感受野识别深度的上限阈值。
  - 超参数：
    - upper_threshold：障碍物识别深度上限阈值。

## Ⅱ 技术报告 Technical Report

### 核心寻球过程

#### PID控制器

- 作用：控制机器狗追球的姿态，使得机器狗在发现球后能稳定地行至球前。
- 目标：RGB相机识别到的球在视野中央
- 误差：球当前位置与目标的距离，代码中已做归一化处理，误差计算的范围在为（-1,1）
- 采样：每0.1秒采样一次当前的状态（球的位置）。
- 执行：控制狗的Z轴旋转方向及速度（$V_x$不变）。当PID控制器的输出为负值时，表明球在视野右侧，此时调整Z轴旋转值为负值（在输出基础上乘以一个比例项，用来规整执行端的输入），从而机器狗向右转，当PID控制器的输出为正值时，情况相反。
- PID参数：
  - $K_p$ = 0.7，调整参数后响应时间合理，震荡或不稳定的情况出现较少。
  - $K_i$= 0.05，开始时没有加积分系数，发现球在视野侧方时很难误差难以消除，因此加上积分项以消除持续的稳态误差。
  - $K_d$ = 0.1，加上微分系数使得PID控制器对机器狗的突变移动得以及时的响应。

#### RGB相机球检测

- 采取基本的掩膜设计，通过上下限滤色，获取掩膜空间。

- 针对球检测，需要稳定性和高效性，因此选择对掩膜空间进行中值滤波，去除噪声，使得掩膜空间更加平滑。

- 获得滤波后的掩膜后，对其进行连通区域的轮廓检测，针对轮廓内区域进行像素面积滤值和最大像素面积检测，期望得到目标球的最大置信区域。

- 对于获得的区域，进行圆形检测判断，通过获取区域的最小包围圆，然后进行区域面积与最小包围圆面积的比例检测，从而保障球检测的可靠性。

### 部分代码详解

#### Code Snippet 1

```python
hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
lower_blue = np.array([90, 68, 64])  # l_h, l_s, l_v
upper_blue = np.array([144, 255, 255])  # u_h, u_s, u_v
mask1 = cv2.inRange(hsv, lower_blue, upper_blue)
mask = cv2.medianBlur(mask1, 9)
result = cv2.bitwise_and(frame, frame, mask=mask)
```

这部分代码首先将获取的图像转换为HSV颜色空间，然后定义了经过试验确定的蓝色目标颜色范围。

<img src="README/image-20230509112357427.png" alt="image-20230509112357427" style="zoom:100%;" align="left" />

之后使用`cv2.inRange()`函数根据颜色范围创建掩膜（mask1），将目标颜色的像素设为255，其余像素设为0。

随后，使用中值模糊（`medianBlur`）方法对掩膜进行平滑处理，以去除噪声。经过反复实验比较效果，将滤波核尺寸确定为9。

最后，通过`cv2.bitwise_and()`函数将掩膜应用于原始图像，以提取出目标颜色的区域便于观察调试。

#### Code Snippet 2

```python
if L == 0:
    print("Region => None")
    return False, center, radius

# 寻找最大面积区域
for i in range(L):
    # cnt表示第i个色块的轮廓信息
    cnt = contours[i] 
    # 计算第i个色块的面积
    area = cv2.contourArea(cnt)  

    if area < area_threshold:
        continue
    if area > max_area:
        max_area = area
        max_idx = i

# 筛选出来最大面积轮廓
if max_area != 0:
    cnt = contours[max_idx]
    (x, y), radius = cv2.minEnclosingCircle(cnt)
    center = (int(x), int(y))
    radius = int(radius)

    area_predict = math.pi * radius*radius
    # 描述形状
    print("MAX_AREA => ", int(max_area), int(area_predict),
            '{:.2f}'.format(max_area/area_predict))
    area_ratio = max_area/area_predict
    print("Circle =>", center, radius)

    # 画出拟合的外接圆
    cv2.circle(frame, center, radius, (0, 255, 0), thickness=2)
    cv2.drawContours(frame, cnt, -1, (0, 0, 255), thickness=2)

    self.contour = cnt
    if area_ratio > 0.50:
        return True, center, radius
```

在此部分代码中，使用for循环遍历每个检测到的轮廓。cnt表示第i个色块的轮廓信息。然后使用`cv2.minEnclosingCircle()`函数计算出包围该轮廓的最小外接圆，获取圆心坐标(x, y)和半径radius。center变量保存下了圆心的整数坐标。半径radius信息在复赛中未用到，在后续比赛中可以加以应用。接下来，输出每个中心点的坐标，以便进行调试和分析。然后重新计算掩膜和结果图像，以便在下一次循环时使用。

<img src="README/984f21d736deb09778a4aa5bbce22f1.jpg" alt="984f21d736deb09778a4aa5bbce22f1" style="zoom: 19%;" />

然后，使用条件语句判断圆心坐标是否位于非安全区内，安全区的划分如上图所示。如果满足条件，`return True`。

如果没有找到符合条件的目标，说明目标未到非安全区，返回`return False`。

综上，本组的目标识别代码使用了OpenCV库中的多种方法，包括颜色空间转换、掩膜创建、中值模糊以及轮廓检测等，通过检测目标的中心点坐标并判断其是否位于特定范围内，以便进行后续决策。

#### Code Snippet 3

```python
class PIDController:
    """
    PID控制类
    * update: PID信息更新
    * reset: PID信息重置
    """
    
    def __init__(self, Kp=0.7, Ki=0.05, Kd=0.1, target=1.0):
        """
        Args:
            kp (float): 比例系数
            ki (float): 比例积分系数
            kd (float): 比例微分系数
            target (float): 目标修正值 
        """
        
        self.Kp = Kp
        self.Ki = Ki
        self.Kd = Kd
        self.target = target

        self.integral = 0
        self.previous_error = 0

    def update(self, current_value, dt=1):
        error = self.target - current_value
        self.integral += error * dt
        derivative = (error - self.previous_error) / dt
        output = self.Kp * error + self.Ki * self.integral + self.Kd * derivative
        self.previous_error = error
        return output

    def reset(self):
        self.integral = 0
        self.previous_error = 0

# Method类中的初始化与方法
self.pid = PIDController(Kp=0.7, Ki=0.05, Kd=0.1, target=1.0)
def follow_ball(self):
    self.pid.reset()
    while True:
        # no obstacle, then pid_control to follow ball
        region, center, radius = self.perception.rgb_info_ball()

        if self.perception.depth_info_ball(center, radius):
            break

        input = center[0] / 320
        # 球丢失了(在走的过程中可能被箱子挡住了)，那就默认球在中央
        if not region:
            input = 1

        out = self.pid.update(input, dt=0.5)
        print("PID out => ", out, "==============")
        # rotate_ratio = 0.30
        rotate_ratio = 0.50
        vx_ratio = 0.19
        vy_ratio = 0.00
        self.update_para(vx=vx_ratio, vy=min(vy_ratio * out, vy_ratio),
                         ang_z=min(rotate_ratio * out, rotate_ratio), gait='', delta=0.1)
        print("Para =>", self.parameters)
        self.action()
```





## Ⅲ 测试与改进

### 测试方法

通过枚举各种可能的测例进行测试，已经测试过的测例包括但不限于：

<img src="README/f2bee5ab166e03c16956e97e3f8e4ea.jpg" alt="f2bee5ab166e03c16956e97e3f8e4ea" style="zoom: 25%;" />

### 改进思路

### 工作日志

#### 总结1 3月31日

要写技术文档，所以为了提前记录，在学习过程中随手把命令和代码整理下来，后续方便整理.所有的代码和cmd每一行（除非比较简单）都要加注释.注释使用上行注释的方法（即在代码上面一行）且 井号后面加一个空格，注释末尾无句号和点号，中间若有分段用逗号隔开

目前的任务有三个：

1. 明白基本原理
2. 实现机器狗上视摄像头的调用以及视频录制，（核心是如何将ros指令转换成python代码）
3. 实现机器狗的视觉识别+前进（即通过视觉判断方向后前进，到目标点后趴下，然后起身返回）

#### 总结2 4月1日

1. 测试了前视摄像头
2. 熟练使用了一系列指令

```sh
# 查看目前运行中的话题以及话题类型
ros2 topic list-t
# 查看某个话题的发布频率使用
ros2 topic hz <topic_name>
# 查看话题信息使用
ros2 topic info <topic_name>
# 订阅话题并打印话题数据
ros2 topic echo <topic_name>
```

3. 测试了上视摄像头

```sh
# 上视相机操作
ros2 service call /mixxxxxxxx/camera_server/change_state life_cycle_msgs/srv/ChangeState “transition: {id: 1}”
ros2 service call /mixxxxxxxx/camera_server/change_state life_cycle_msgs/srv/ChangeState “transition: {id: 3}” 
ros2 service call /mixxxxxxxx/camera_service interaction_msgs/srv/CameraService “{command: 7}”
ros2 topic echo /mixxxxxxxx/h264_video
```

目前遇到的问题是 `h264_video.data`中的`CompressedImage`格式数据通过 `cv2.imdecode()`之后会变成`None`值。因此无法显示

4. 下一步任务

- 复赛题目：狗子从原点出发前进，遇到移动的红蓝目标，选择合适的速度进行穿越，成功穿过红蓝目标无碰撞则成功。

- 复赛思路：平视摄像头+颜色识别+深度测距+速度调节

  - \action 板块
  - \camera\color 板块
  - \camera\depth 板块（目前尚不知道怎么用的） `CameraInfo`格式的数据(不知道摄像机标定的同学可以了解一下摄像机标定)

- 下一步任务：

  - 学习ROS2 否则现场调试效率低下

    - ROS2 教程 

      [教程 — ROS 2 documentation 文档 (fishros.com)](http://dev.ros2.fishros.com/doc/Tutorials.html)

      [ROS2中文网 | ROS2 中文网 (fishros.com)](http://dev.ros2.fishros.com/)

      [【古月居】古月·ROS2入门21讲 | 带你认识一个全新的机器人操作系统_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV16B4y1Q7jQ/?spm_id_from=333.337.search-card.all.click&vd_source=ea3fb2320c8061a1b4713de34687980c)

  - 学习python (如果以前没用过python的话)

    - 只需要学学数据类型、常用库及其引用方法、基本语法（条件判断、循环等）、面向对象（如何写类以及`__init__`等类内函数的作用

  - 写`.sh`文件的使用方法(bonus项，内容不多，由史明磊完成)

  - 写4月1日debug的技术文档(由杨朔完成)

#### 总结3 4月6日

1. 进行了初赛验收
2. 分配了写技术报告的任务
3. 联动了摄像头和前进

#### 总结4 4月12日

第二次培训

1. 复赛闯关比赛任务
2. opencv目标检测、跟踪方法详解（基础方法）
3. 一些神经网络模型目标检测、跟踪方法介绍（进阶方法）


#### 总结5 4月24日

紫荆2号楼小组内讨论

1. 讨论复赛闯关比赛任务解决方案
2. 感知：opencv目标检测、跟踪方法详解（基础方法）
3. 决策：分6阶段
   1. 起步阶段：主要听从裁判指令
   2. **直走阶段**：主要是靠近目标阶段，该阶段任务轻松，只需要走直线即可。
   3. **过渡阶段**：识别并获取各类信息，提前为决策收集信息并做简易决策。
   4. **决策阶段**：做出决策
      1. 决策1：等待火线区域中的狗行动到足以让己方穿越。
      2. 决策2：获取决策1的指令后开始按照给定参数穿越。
   5. 穿越阶段：直走以最安全、最快速度穿越。
   6. 终止阶段：穿过火线区域后在终止区域趴下。
4. 决策参数：
   1. 直走阶段的距离与速度
   2. 过渡阶段的距离与速度
   3. 决策阶段的距离与速度
   4. 如果要用PID算法的话：PID算法的KP\KI\KD
5. 任务：
   1. 做通信任务：远程链接
   2. 做决策任务：完成直走阶段、过渡阶段和决策阶段的参数和算法设置
   3. 由宋宸韬、祝德艺、杨朔负责该阶段任务的完成，史明磊、彭怀玉协助
   4. 彭怀玉、史明磊撰写该阶段的所有日志

#### 总结6 5月6日

1. 进行了最终复赛任务的参数设计
2. 多次重复完成复赛任务，确保稳定性

#### 总结7 5月7日

1. 进行了复赛验收
2. 分配了写技术报告的任务
3. 联动了深度摄像机、RGB摄像机和行动
4. 制定了下一阶段的任务


#### 总结8 5月13日

1. 使用平均的思想调了深度相机，并且取得了一定精度。实现了横移避障。
2. 重新测定了球的颜色区间。发现狗的颜色识别相比人眼H值会下调约50。
3. 完成了决赛的入门任务1、2
4. 进行了决赛策略的探讨
5. 指定任务：

- 规划决赛找球策略

- 对策略评定并调参

- 提高策略鲁棒性

#### 总结9 5月16日

1. 进行了决赛前任务的验收

-  横向避障

-  靠近小球停下

2. 面对Box时的旋转避障

3. 鉴于碰撞一次箱子所罚秒数较少，权衡利弊后，决定将“找到目标状态”的策略更新为：看到球之后就不再避障，直接PID找球 。

#### 总结10 5月16日 

整个过程分为 “未找到目标状态”与“找到目标状态”两部分。

##### 未找到目标状态

在“未找到目标状态”中，狗向前直走，一旦遇到障碍物，就停下来，开始原地逆时针转圈。转到前方没有障碍物之后，可以再转一小段时间以防止边缘擦碰障碍物，然后继续往前直走，遇到障碍物再逆时针转圈，如此循环。同时，选择合适的时机进行原地360°转圈扫视。整个过程中，一旦发现小球，就进入“找到目标状态”。

##### 找到目标状态

在“找到目标状态”中，如果遇到障碍物，躲避的方式是横向往球的方向平移躲避，以减小丢失目标或撞击箱子的可能性。

###### 细节内容

1. 找到球并且停下来的精度 （群策群力）
   1. 识别图片里球状颜色块的面积像素面积和区域坐标，杨朔
   2. 补全这个圆形
2. 避障情形的设定和策略
   1. 德艺和怀玉 （策略）
      我们今天讨论了一个大致的思路。整个过程分为
      1. “未找到目标状态”
         1. 在“未找到目标状态中”，狗向前直走，一旦遇到障碍物，就停下来，开始原地逆时针转圈。转到前方没有障碍物之后，（可以再转一小段时间（防止边缘擦碰障碍物）），就继续往前直走，遇到障碍物再逆时针转圈，如此循环。同时，选择合适的时机进行原地360°转圈扫视。整个过程中，一旦发现小球，就进入“找到目标状态”。
         2. “找到目标状态”。在“找到目标状态中”，如果遇到障碍物，躲避的方式是横向往球的方向平移躲避，以减小丢失目标或撞击箱子的可能性。
3. 2023年5月17日 （宋宸韬测试）
   1. 避障情形的设定与测试

> 决赛阶段安排
>
> 5-23 周二 杨朔 怀玉 德艺 + 谁有空就可以来
> 5-24 周三 韬韬 史明磊 + 谁有空就可以来
> 5-24 周四 史明磊 杨朔 + 韬韬 谁有空就可以来
> 5-25 周五 德艺史明磊 韬韬 怀玉
> 5-26 周六 怀玉 + 全体

#### 总结11 5月23日

今日工作
调整policy

1. 开始时逆时针旋转90°寻球，找到球则追球
2. 连续前行15s(约场地长度一半)时进行360°旋转寻球，找到则追
3. 优化pid追球部分，在追球过程中加入z轴旋转

场地北面的黄色地块(估计还是蓝色反光的问题)会对球的识别有影响(今天是加大了蓝色面积的阈值)

狗靠墙边(或者箱子)走的时候容易碰到箱子，应该是离箱子太近了。

pid追球的时候z轴旋转的参数可以再调调

#### 总结12 5月24日

- 通过修复感受野的范围bug减少了靠箱子边走时碰箱子的情况。

- 为了解决追球过程不太流畅的问题，进一步优化了PID参数。

- 实测发现视野中同时有很近的障碍物和球时狗有概率直接趴下，但此时与球的距离尚未达到要求。通过增加最小阈值的判定减少了该情况的出现频率。

- 实测发现狗在一开始旋转90°过程中有概率看不到视野内的目标，通过添加等待时间修复了该情况。

- 通过对几种复杂情形进行测试，为了提高效率，决定将连续直行一定时间后360°转圈调整为120°转圈。

#### 总结12 5月25日

今日工作：

1. 通过修复感受野的范围bug减少了靠箱子边走时碰箱子的情况
2. 调整pid参数，使追球过程更流畅（今天测试情况有限，需要进一步调节）
3. 通过增加最小阈值的判定改善了视野中同时有很近的物体和球时狗直接趴下的情况（但是情况仍然会有出现）
4. 通过添加等待时间修复了狗一开始在转90度时识别不到球的情况
5. 测试了几种较复杂情况，走一定时间后转120度的策略效果很好

问题：

1. 识别球的问题：视野中同时有很近的物体和球时，狗直接趴下的情况（可能缩小球深度采样区域的范围能改善？）、以及黄色地面影响狗判断的情况还有发生
2. pid有时会z轴旋转过度，需进一步调节
3. 旋转避障时会擦箱子边，计划稍微增加旋转角度

###### 细节改进

- 为了应对球一开始就在视野内的情况，将效率最大化，加入策略：在一开始先原地旋转90°，该过程中若能看到球，直接出发进行PID跟踪。
- 将360°转圈扫视的时机确立为连续直行达到15秒（实际行进距离约场地长度一半）时，以应对球位于场地中央的情况，保证狗不会始终因为看不到球而一直沿着场地外围转圈。
- 由于原来的PID追球算法中只包含对y方向速度的调控，效率一般，狗在追踪球时有概率丢失目标或侧向碰撞箱子，于是决定在PID算法中新增对z方向速度的控制，狗可以一边前进一边旋转，保证了追踪过程的稳定性与高效性。

#### 总结13 5月26日

修复问题
问题：

1. 识别球的问题：视野中同时有很近的物体和球时，狗直接趴下的情况（可能缩小球深度采样区域的范围能改善？）： 通过设置mask确定球形区域来缓解以及黄色地面影响狗判断的情况还有发生：（暂时还没解决，希望请求老师遮蔽）
2. pid有时会z轴旋转过度，需进一步调节，（暂时缓解，PID测试时稳定性尚可）
3. 旋转避障时会擦箱子边，计划稍微增加旋转角度（通过设置二郎神“三感受野结构缓解”）

今日任务完成情况：

1. 设置了新的步态
2. 调节了速度并进行了参数调整（参数包括：感受野区域面积、PID参数、x,y,ang_z速度值）
3. 增加了横向三感受野
4. 调整了部分函数，新增了部分成员变量，使得结构更加完善

下次任务：

1. 测试更多情境，期望发现更多问题
2. 微调数值

###### 细节改进

- 为了进一步减少“视野中同时有很近的障碍物和球时狗有概率直接趴下”的情况，决定设置mask确定球形区域。

- 为了提高找球效率，设置了新的步态，调节了感受野区域面积、PID参数、x,y,ang_z速度值等参数，暂时缓解了PID追踪过程中z方向旋转过度的问题。

- 为了提高避障效果与看见球的可能性，增加了横向三感受野。

- 为了使代码结构更加完善，调整了部分函数，新增了部分成员变量。

- 实测发现狗在旋转避障过程中由于视野有限可能与周围的障碍发生剐蹭，为了减少这种情况，引入了在旋转过程中距离前方障碍物过近时的后退动作。

#### 总结14 5月27日

- 如果看到球就不考虑避障，一旦与其他狗发生碰撞，会被直接罚下。因此，通过研究狗和箱子各自的特点，引入了利用深度数据区别狗和箱子的机制。若前方的障碍是狗，则优先考虑避障。

- 鉴于老师在群里提到狗的出发角度由裁判指定，放弃了出发前先旋转90°扫视的策略。

- 为了降低后退过程中碰到障碍的概率，调小了后退距离。



## Ⅳ 附录 Appendix

#### 第11组信息 Team 11 Infomation

| 班级 Class | 姓名 name |
| :--------: | :-------: |
|    自15    |  史明磊   |
|    自15    |  祝德艺   |
|    自15    |  宋宸韬   |
|    自15    |   杨朔    |
|    自15    |  彭怀玉   |

